{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "Convolutional neural network (later in notebook as *CNN*) owes it's name after convolution blocks. Today I will explain you how does convolution block work and how to use them in neural network in order to create *CNN*.\n",
    "***\n",
    "Table of contents\n",
    " - convolution block\n",
    " - max pooling\n",
    " - dropout regularization\n",
    " - exercise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution block\n",
    "\n",
    "![](images/kernel.gif)\n",
    "\n",
    "![](images/conv.gif)\n",
    "\n",
    "$ \\\n",
    "\\hat{y}(i, j) = \\omega * f(i,j) = \\sum_{da=-a}^{a} \\sum_{db=-b}^b \\omega(da, db)f(i + da, j + db)\\\\\n",
    "\\omega \\to kernel \\\\\n",
    "\\omega_{{a}\\times{b}} = \\begin{bmatrix} \\omega_{1,1} & ... & \\omega_{1,b} \\\\ . & . & . \\\\ \\omega_{a,1} & . & \\omega_{a,b} \\end{bmatrix}\\\n",
    "$  \n",
    "\n",
    "In convolution block we take vector of kernels.\n",
    "\n",
    "![](images/conv_bl.gif)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(28, 28, 1)\n",
    "kernel_size=(3, 3)\n",
    "kernel_num = 32\n",
    "layers.Conv2D(kernel_num, kernel_size, activation='relu', input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "out_channels = 8\n",
    "kernel_size = 2\n",
    "nn.Conv2d(in_channels, out_channels, kernel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max pooling\n",
    "\n",
    "![](images/pooling.gif)\n",
    "\n",
    "Here we move our kernel just like in convolution block but this time we only take max value of kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = (2, 2)\n",
    "m = layers.MaxPooling2D(pool_size)\n",
    "inp = tf.constant([[0, 0, 1, 1],\n",
    "                  [1, 4, 5, 3],\n",
    "                  [6, 0, 2, 4],\n",
    "                  [0, 4, 3, 10]])\n",
    "print(inp)\n",
    "print(\"-\" * 50)\n",
    "print(f\"Max pooling {pool_size}\")\n",
    "inp = tf.reshape(inp, (1, 4, 4, 1))\n",
    "out = m(inp)\n",
    "out = tf.reshape(out, (2, 2))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.MaxPool2d(pool_size)\n",
    "\n",
    "inp = torch.randn(1, 4, 4)\n",
    "print(inp.shape)\n",
    "print(inp[0])\n",
    "out = m(inp)\n",
    "print(\"-\" * 50)\n",
    "print(f\"Max pooling {pool_size}\")\n",
    "print(out.shape)\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "This time we will be using *MNIST* dataset. Next time we will be using something more challenging\n",
    "\n",
    "I want you to complete implementation of convolutional neural networks.\n",
    "You can choose two frameworks to implement your solution *tensorflow* or *pytorch*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, x_test = x_train.reshape(-1, 28, 28, 1), x_test.reshape(-1, 28, 28, 1)\n",
    "y_train, y_test = np_utils.to_categorical(y_train), np_utils.to_categorical(y_test)\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "\n",
    "model = models.Sequential([\n",
    "    # Complete your model implementation\n",
    "    # Remember about shapes!!!\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = 'adam'\n",
    "loss = losses.CategoricalCrossentropy(from_logits=True)\n",
    "metrics=['accuracy']\n",
    "epochs = 2\n",
    "batch_size = 8\n",
    "\n",
    "model.compile(optimizer, loss, metrics)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_test[0]\n",
    "img = img.reshape(1, 28, 28, 1)\n",
    "\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "model.predict(img)[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, x_test = x_train.reshape(-1, 1, 28, 28), x_test.reshape(-1, 1, 28, 28)\n",
    "\n",
    "num_classes = 10\n",
    "batch_size = 4\n",
    "epochs = 2\n",
    "\n",
    "def data_generator(x, y):\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        yield torch.from_numpy(x[i:i+batch_size%len(x)]).float(), torch.from_numpy(y[i:i+batch_size%len(x)]).long()\n",
    "    \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Complete model implementation\n",
    "        # Remeber about shapes! You may use below example\n",
    "        # self.conv1 = nn.Conv2d(inp_channels, out_channels, kernel_size)\n",
    "        # self.pool = nn.MaxPool2d(pool_size)\n",
    "        # self.conv2 = nn.Conv2d(inp_channels, out_channels, kernel_size)\n",
    "        # self.fc1 = nn.Linear(last_size * last_kernel_size * last_kernel_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # x = x.view(-1, last_size * last_kernel_size * last_kernel_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss = 0.0\n",
    "    step = 1\n",
    "    for batch, labels in data_generator(x_train, y_train):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(batch)\n",
    "        batch_loss = criterion(outputs, labels) \n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss += batch_loss.item()\n",
    "        if step % 1000 == 0:\n",
    "            print(f\"({epoch}, {step * batch_size}) loss: {loss:.3f}\")\n",
    "            loss = 0\n",
    "            \n",
    "        step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_test[0]\n",
    "\n",
    "plt.imshow(img.reshape(1, 28, 28, 1)[0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "img = img.reshape(1, 1, 28, 28)\n",
    "net(torch.from_numpy(img).float()).detach().numpy().argmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
